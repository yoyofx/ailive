{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åˆå§‹åŒ–Lanchain\n",
    "# å®‰è£…ä¾èµ–\n",
    "* è¿è¡Œç¯å¢ƒ: python 3.11.8 , conda\n",
    "* å¼€å‘ç¯å¢ƒ: langchain v0.1.11 , openai v0.28.1\n",
    "```sh \n",
    "conda install langchain -c conda-forge\n",
    "conda install openai==v0.28.1 -c conda-forge\n",
    "conda install Chroma\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN apt-get update -y && apt-get install libmagic1 libmagic-dev -y\n",
    "%pip install python-magic-bin==0.4.14\n",
    "%pip install python-libmagic\n",
    "%pip install unstructured\n",
    "%pip install bilibili-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain-openai\n",
    "%pip install Chroma\n",
    "%pip install -U duckduckgo-search\n",
    "%pip install faiss-cpu\n",
    "%pip install huggingface-hub\n",
    "%pip install -U langchain-community faiss-cpu langchain-openai tiktoken\n",
    "%pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (ChatPromptTemplate,PromptTemplate,SystemMessagePromptTemplate,\n",
    "                               AIMessagePromptTemplate,HumanMessagePromptTemplate,)\n",
    "from langchain.schema import ( HumanMessage, SystemMessage, AIMessage )\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from lang_funcs import read_toml,create_llm_openai\n",
    "import os\n",
    "\n",
    "config = read_toml(\"./config.toml\")\n",
    "\n",
    "chat = create_llm_openai( apikey=config[\"openai\"][\"api_key\"],\n",
    "                         apibase=config[\"openai\"][\"url\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoyofx/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict_messages` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='æˆ‘ä¸çŸ¥é“' response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chat.predict_messages([\n",
    "  SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªå¯¹äººå·¥æ™ºèƒ½ä¸€æ— æ‰€çŸ¥çš„èŠå¤©æœºå™¨äººã€‚å½“ä½ è¢«é—®åŠäººå·¥æ™ºèƒ½æ—¶ï¼Œä½ å¿…é¡»è¯´â€œæˆ‘ä¸çŸ¥é“â€\"),\n",
    "  HumanMessage(content=\"ä½ çŸ¥é“ä»€ä¹ˆæ˜¯AIå—?\")\n",
    "])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ ä»Šå¤©æ—©ä¸Šåƒäº†å—ï¼Ÿ' response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "system_template=\"You are a professional translator that translates {src_lang} to {dst_lang}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template=\"{user_input}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "message = chat_prompt.format_prompt(\n",
    "    src_lang=\"English\",\n",
    "    dst_lang=\"Chinese\", \n",
    "    user_input=\"Did you eat in this morning?\"\n",
    ").to_messages()\n",
    "\n",
    "response = chat.predict_messages(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoyofx/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hex code for the color green is #008000.\n",
      "The hexadecimal code for the color red is #FF0000. In hexadecimal notation, colors are represented using a combination of six digits, where each pair of digits represents the intensity of red, green, and blue (RGB) in the color. In this case, the red intensity is at its maximum, while green and blue intensities are at their minimum, resulting in the color red.\n",
      "The hex code for the color yellow is #FFFF00.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"color\"],\n",
    "    template=\"What is the hex code of color {color}?\",\n",
    ")\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "\n",
    "print(chain.run(\"green\"))\n",
    "print(chain.run(\"red\"))\n",
    "print(chain.run(\"yellow\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, LangChain!', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Hey!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Where are you?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='By your side', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory( k=1)\n",
    "memory.save_context({\"input\": \"Hi, LangChain!\"}, {\"output\": \"Hey!\"})\n",
    "memory.save_context({\"input\": \"Where are you?\"}, {\"output\": \"By your side\"})\n",
    "\n",
    "memory.chat_memory.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mæˆ‘éœ€è¦æŸ¥ä¸€ä¸‹ä¸­å›½å°Šå’Œå“ˆåˆ©æ³•å¡”çš„é«˜åº¦ï¼Œç„¶åæ¯”è¾ƒå®ƒä»¬çš„å·®è·ã€‚\n",
      "Action: duckduckgo_search\n",
      "Action Input: ä¸­å›½å°Šé«˜åº¦\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mæœ¬é¡µé¢åˆ—ä¸¾äº†ä¸­å›½å¤§é™†ç›®å‰æœ€é«˜çš„10åº§é«˜æ¥¼ï¼ŒåŒ…æ‹¬ä¸Šæµ·ä¸­å¿ƒå¤§å¦ã€å¹³å®‰é‡‘èä¸­å¿ƒã€é«˜é“¶é‡‘è117ã€å¹¿å·å¡”ç­‰ï¼Œä»¥åŠå…¶ä»–æ¸¯æ¾³å°åœ°åŒºçš„ä¸¤åº§é«˜æ¥¼ã€‚æ¯åº§é«˜æ¥¼éƒ½æœ‰å…¶é«˜åº¦ã€åŸå¸‚ã€å»ºæˆå¹´ä»½ã€è®¾è®¡ç‰¹ç‚¹å’Œè§‚å…‰å…ç­‰ä¿¡æ¯ï¼Œä¾›é«˜æ¥¼çˆ±å¥½è€…å’Œå»ºç­‘çˆ±å¥½è€…å‚è€ƒã€‚ ä¸Šæµ·ä¸­å¿ƒå¤§å¦ æ ‡å‡†é«˜åº¦ï¼š 632 ç±³ (2073 è‹±å°º) å±‹é¡¶é«˜åº¦ï¼š 587 ç±³ æ¥¼å±‚æ•°ï¼š 128 è§‚å…‰å…é«˜åº¦ï¼š 552 ç±³ ç”¨é€”ï¼š åŠå…¬ï¼Œé…’åº—ï¼Œè§‚å…‰ï¼Œä¹¦åº—ï¼Œåšç‰©é¦†ï¼Œé›¶å”® å»ºæˆå¹´ä»½ï¼š 2015 æ‰€åœ¨åŸå¸‚ï¼š ä¸Šæµ· ä¸­å›½å°Šé«˜åº¦528ç±³ï¼Œåœ°ä¸Š108å±‚ï¼Œåœ°ä¸‹7å±‚ã€‚ å…¶è‡ªä¸‹è€Œä¸Šçš„è±å½¢æœºç†ï¼Œæºäºä¸­å›½ä¼ ç»Ÿå™¨çš¿ä¹‹ä¸€â€”â€”ç«¹å™¨ã€‚ ä¸­å›½äººçˆ±ç«¹ï¼Œç«¹æ¯”ä½œå›å­ï¼Œæ·¡é›…æœ‰æ°”èŠ‚ï¼Œè‡ªå¤æœ‰\"ä¸å¯å±…æ— ç«¹\"ä¹‹è¯­ã€‚ å»ºç­‘é¡¶éƒ¨çš„ç©ºé—´è®¾è®¡å–è‡ª\"å­”æ˜ç¯\"çš„å½¢æ€æ„å‘ï¼Œå‘ˆå†‰å†‰ä¸Šå‡ä¹‹æ€ã€‚ åœ¨æŸ”ç¾è€Œèµ‹æœ‰å¯“æ„çš„å¤–å½¢è®¾è®¡ä¸‹ï¼ŒæŠ€æœ¯çš„æ›´æ–°è¿ç”¨ä¹Ÿè®©\"ä¸­å›½å°Š\"æœ‰äº†æ›´å¤šäº®ç‚¹ï¼Œå–å¾—äº†å¤šä¸ªä¸–ç•Œç¬¬ä¸€ã€‚ æ™ºèƒ½é¡¶å‡é’¢å¹³å°ã€æ°¸ä¸´ç»“åˆæ¶ˆé˜²ç³»ç»Ÿã€BIMæŠ€æœ¯å…¨å‘¨æœŸåº”ç”¨ã€å®Œå–„çš„æ¶ˆé˜²ç³»ç»Ÿã€æŠ—éœ‡èƒ½åŠ›ã€ä½ç¢³ç¯ä¿çš„è®¾è®¡è´¯ç©¿äºä¸­å›½å°Šå„ä¸ªç»†èŠ‚ä¸­ï¼Œé€šè¿‡è°ƒèŠ‚å»ºç­‘ç‰©çš„é«˜åº¦ç»“æ„å’Œæ–¹ä½æœå‘ï¼Œå……åˆ†åˆ©ç”¨å†¬å­£é˜³å…‰å’Œå¤å­£è‡ªç„¶é£çš„æµåŠ¨ï¼›å»ºç«‹èµ·ä¸€å¥—åŒºåŸŸèƒ½æºç³»ç»Ÿï¼Œå®ç°åŒºåŸŸé›†ä¸­ä¾›å†·ä¾›çƒ­ç³»ç»Ÿï¼Œå‡å°‘20%-40%çš„èƒ½æºæ¶ˆè€—ã€‚ æ­¤å¤–ï¼Œä¸­å›½å°Šä½¿ç”¨çš„ç”µæ¢¯æ˜¯ä¸–ç•Œé¦–åˆ›çš„æœåŠ¡é«˜åº¦è¶…500ç±³è·ƒå±‚ç”µæ¢¯ã€‚ ğŸ‰ç­”æ¡ˆæ˜¯ï¼šç›®å‰ï¼Œä¸­å›½å°Šä½œä¸ºå•†åŠ¡åŠå…¬å¤§æ¥¼ï¼Œå¹¶æœªå‘å…¬ä¼—å¼€æ”¾è§‚å…‰æœåŠ¡ï¼Œä¸»è¦æ¥å¾…çš„æ˜¯å†…éƒ¨å·¥ä½œäººå‘˜ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œæš‚æ—¶æ— æ³•åƒæ¸¸è§ˆå…¶ä»–åŸå¸‚è§‚æ™¯å°é‚£æ ·ï¼Œç™»ä¸Šä¸­å›½å°Šé¡¶ç«¯é¥±è§ˆäº¬åŸç¾æ™¯ã€‚ è¯¥å¤§å¦åè½åœ¨åŒ—äº¬å¸‚å•†åŠ¡ä¸­å¿ƒåŒºçš„æ ¸å¿ƒåœ°å¸¦ï¼Œä¸œèµ·é‡‘å’Œä¸œè·¯ï¼Œå—æ¥è§„åˆ’ä¸­çš„ç»¿åœ°ï¼Œè¥¿è‡³é‡‘å’Œè·¯ï¼ŒåŒ—é å…‰åè·¯ã€‚ ğŸŒˆå°½ç®¡å¦‚æ­¤ï¼Œ\"ä¸­å›½å°Š\"çš„å»ºç­‘è®¾è®¡å’Œå·¥ç¨‹æˆå°±ä»ç„¶å€¼å¾—æˆ‘ä»¬ä¸€æ¢ç©¶ç«Ÿã€‚ å…¶è®¾è®¡ç†å¿µæºè‡ªä¸­å›½å¤ä»£ç¤¼å™¨\"å°Š\"ï¼Œå¯“æ„ç€åº„é‡ä¸å´‡é«˜ã€‚ å»ºç­‘å¤–å½¢è‡ªä¸‹è€Œä¸Šé€æ¸æ”¶ç´§å†æ”¾å¤§ï¼Œå½¢å¦‚å¤ä»£é…’å™¨\"æ¨½\"ï¼ŒåŒæ—¶èå…¥äº†ç«¹ç¼–ã€å­”æ˜ç¯ä»¥åŠåŸé—¨ç­‰ä¸­å›½ä¼ ç»Ÿå…ƒç´ ï¼Œå·§å¦™åœ°å°†ä¸œæ–¹ç¥éŸµä¸ç°ä»£æ‘©å¤©å¤§æ¥¼ç›¸ç»“åˆã€‚ ğŸ’¡å€¼å¾—ä¸€æçš„æ˜¯ï¼Œ\"ä¸­å›½å°Š\"åœ¨å·¥ç¨‹æŠ€æœ¯æ–¹é¢åˆ›ä¸‹äº†å¤šé¡¹ä¸–ç•Œä¹‹æœ€å’Œå›½å†…çºªå½•ã€‚ ä¸‰ã€æ€»ç»“ åŒ—äº¬ä¸­å›½å°Šçš„ç»“æ„ä¸åŠ›å­¦ä¹‹ç¾ä¸ä»…ä»…ä½“ç°åœ¨å…¶å¤–è§‚ä¸Šï¼Œæ›´ä½“ç°åœ¨å…¶å†…åœ¨çš„è®¾è®¡ç†å¿µå’Œæ–½å·¥æŠ€æœ¯ä¸Šã€‚ å®ƒæ˜¯ä¸­å›½å»ºç­‘æŠ€æœ¯å‘å±•çš„ä¸€ä¸ªç¼©å½±ï¼Œä¹Ÿæ˜¯ä¸–ç•Œå»ºç­‘å²ä¸Šçš„ä¸€ä¸ªæ°ä½œã€‚é€šè¿‡è§£æ„å…¶ç»“æ„ä¸åŠ›å­¦ä¹‹ç¾ï¼Œå¯ä»¥æ›´åŠ æ·±å…¥åœ°äº†è§£è¿™åº§å»ºç­‘çš„é­…åŠ›å’Œä»·å€¼ã€‚\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mæˆ‘éœ€è¦æŸ¥ä¸€ä¸‹å“ˆåˆ©æ³•å¡”çš„é«˜åº¦ã€‚\n",
      "Action: duckduckgo_search\n",
      "Action Input: å“ˆåˆ©æ³•å¡”é«˜åº¦\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. å“ˆåˆ©æ³•å¡”. å“ˆåˆ©æ³•å¡”. æ ‡å‡†é«˜åº¦ï¼š 828 ç±³ (2717 è‹±å°º) æ€»é«˜åº¦ï¼š 829.8 ç±³ å±‹é¡¶é«˜åº¦ï¼š 585 ç±³ æ¥¼å±‚æ•°ï¼š 163 è§‚å…‰å…é«˜åº¦ï¼š 448 ç±³ & 555 ç±³ å»ºæˆå¹´ä»½ï¼š 2010 ç”¨é€”ï¼š åŠå…¬ï¼Œé…’åº—ï¼Œä½å®…ï¼Œè§‚å…‰ï¼Œä¿¡å·å‘å°„ æ‰€åœ¨åŸå¸‚ï¼š è¿ªæ‹œ å“ˆåˆ©æ³•å¡”å‰ç§°è¿ªæ‹œå¡”ï¼Œè‡ª2009å¹´å»ºæˆä»¥æ¥ä¾æ®æ€»é«˜åº¦å’Œæ ‡å‡†é«˜åº¦ä¸¤ç§æµ‹é‡æ ‡å‡†æµ‹é‡çš„å…¨ä¸–ç•Œ ... å“ˆåˆ©æ³•å¡”çš„é«˜åº¦ä¸ä»…ä»…æ˜¯ä¸ºäº†åˆ·æ–°çºªå½•ï¼Œæ›´æ˜¯ä½“ç°äº†è¿ªæ‹œå¯¹äºå»ºç­‘æŠ€æœ¯å’Œå·¥ç¨‹çš„è¿½æ±‚å’Œçªç ´ã€‚ ä¸ºäº†è¾¾åˆ°è¿™ä¸€é«˜åº¦ï¼Œå·¥ç¨‹å¸ˆä»¬ä¸ä»…ä½¿ç”¨äº†å¤§é‡çš„æ··å‡åœŸå’Œé’¢ç­‹ï¼Œè¿˜åˆ©ç”¨äº†å…ˆè¿›çš„å»ºç­‘æŠ€æœ¯å’Œè®¾å¤‡ï¼Œå¦‚å¤§å‹èµ·é‡æœºå’Œå‚ç›´æ³µç­‰ã€‚ å“ˆåˆ©æ³•å¡”ï¼ˆé˜¿æ‹‰ä¼¯æ–‡ï¼šØ¨Ø±Ø¬ Ø®Ù„ÙŠÙØ©â€ï¼Œæ‹‰ä¸åŒ–ï¼šburj khalifahâ€ï¼Œè‹±æ–‡ï¼šBurj Khalifa Towerï¼‰ï¼ŒåŸåè¿ªæ‹œå¡”ï¼Œåˆç¨± è¿ªæ‹œ å¤§å»ˆæˆ–æ¯”æ–¯è¿ªæ‹œå¡”ã€‚. å“ˆåˆ©æ³•å¡”é«˜828ç±³ï¼Œæ¨“å±¤ç¸½æ•¸162å±¤ï¼Œé€ åƒ¹15å„„ç¾å…ƒï¼Œå¤§å»ˆæœ¬èº«çš„ä¿®å»ºè€—è³‡è‡³å°‘10å„„ç¾å…ƒï¼Œé‚„ä¸åŒ…æ‹¬å…¶å…§éƒ¨å¤§å‹è³¼ç‰©ä¸­å¿ƒã€æ¹–æ³Šå’Œç¨ ... å“ˆåˆ©æ³•å¡”ï¼Œä¸–ç•Œç¬¬ä¸€é«˜æ¥¼!è¿™åº§ä»¤äººæƒŠå¹çš„å»ºç­‘å±¹ç«‹åœ¨é˜¿æ‹‰ä¼¯è”åˆé…‹é•¿å›½çš„è¿ªæ‹œï¼Œé«˜åº¦è¾¾åˆ°äº†æƒŠäººçš„828ç±³ã€‚å®ƒçš„ç‹¬ç‰¹ä¹‹å¤„ä¸ä»…ä»…æ˜¯é«˜åº¦ï¼Œè¿˜åŒ…æ‹¬162å±‚æ¥¼çš„å£®ä¸½è®¾è®¡å’Œè¶…ç°ä»£çš„è®¾æ–½ã€‚ è®©æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹è¿™åº§å»ºç­‘çš„æƒŠäººæ•°æ®ã€‚ä¸ºâ€¦ å“ˆåˆ©æ³•å¡”é«˜828ç±³ï¼ˆ2717è‹±å°ºï¼‰ï¼Œæ˜¯è¿„ä»Šä¸ºæ­¢ä¸–ç•Œä¸Šæœ€é«˜çš„æ‘©å¤©å¤§æ¥¼ï¼Œ2007å¹´ä»å°æ¹¾åŒ—éƒ¨çš„å°åŒ—101å¤§æ¥¼æ‰‹ä¸­æ¥è¿‡äº†å¤´æŠŠäº¤æ¤…ï¼Œå½“æ—¶çš„é«˜åº¦ä¸º509ç±³ï¼Œæœ‰106å±‚ã€‚ å®ƒè¿˜è¶…è¿‡äº†åŠ æ‹¿å¤§å›½å®¶å¡”ç­‰å»ºç­‘ï¼Œå…¶é«˜åº¦è¶…è¿‡553ç±³ï¼Œä»¥åŠç¾å›½å…¨å›½å¹¿æ’­å…¬å¸åœ¨åŒ—è¾¾ç§‘ä»–å·çš„KVLY-TVç”µä¿¡å¡”ï¼Œå…¶é«˜åº¦ ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mç°åœ¨æˆ‘éœ€è¦è®¡ç®—ä¸­å›½å°Šå’Œå“ˆåˆ©æ³•å¡”çš„é«˜åº¦å·®ã€‚\n",
      "Action: Calculator\n",
      "Action Input: 828 - 528\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 300\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mæˆ‘ç°åœ¨çŸ¥é“ä¸­å›½å°Šå’Œå“ˆåˆ©æ³•å¡”çš„é«˜åº¦å·®æ˜¯300ç±³ã€‚\n",
      "Final Answer: 300 ç±³\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'300 ç±³'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = \"socks5h://127.0.0.1:7890\" \n",
    "os.environ['https_proxy'] = \"socks5h://127.0.0.1:7890\" \n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=chat)\n",
    "agent = initialize_agent(tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "agent.run(\"ä¸­å›½å°Šå’Œå“ˆåˆ©æ³•å¡”?å®ƒä»¬ç›¸å·®å¤šé«˜? å®ƒä»¬è°æœ€é«˜? ä½¿ç”¨ä¸­æ–‡å›ç­”,å¹¶è¿”å›æ•°å€¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 document(s) in this document.\n",
      "There are 4240 characters in the first page of your document.\n",
      "Creating the embeddings using FAISS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoyofx/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯¥æ–‡ä»¶æ˜¯å¯¹Maomiå¼€å‘æ¡†æ¶çš„æ–‡æ¡£ã€‚ç”±èµ¤è¤¶å·¥è‰¯æ’°å†™ï¼Œæ¶µç›–äº†æ¨¡å—åŒ–ã€è‡ªåŠ¨æœåŠ¡æ³¨å†Œã€æ•…éšœè¯Šæ–­ã€æ—¥å¿—è®°å½•ã€é…ç½®ã€åºåˆ—åŒ–ã€å¤šè¯­è¨€æ”¯æŒã€HTTPåº”ç”¨ç¨‹åºå¼€å‘ã€äº‹ä»¶æ€»çº¿æ¡†æ¶è®¾è®¡ã€åŠ¨æ€ä»£ç ç”Ÿæˆã€Webæ¡†æ¶å®šåˆ¶å’Œå¯¹è±¡æ˜ å°„æ¡†æ¶ç­‰å„ä¸ªæ–¹é¢ã€‚å®ƒæä¾›äº†å¯¹Maomiè®¾è®¡å’Œå®ç°çš„æ·±å…¥è§è§£ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘äººå‘˜ç†è§£æ¡†æ¶çš„ä½¿ç”¨å’Œè®¾è®¡åŸåˆ™ã€‚è¯¥æ¡†æ¶åŒ…å«62ä¸ªé¡¹ç›®ï¼Œæ¶µç›–äº†è¯Šæ–­å·¥å…·ã€æ—¥å¿—æ¡†æ¶å’Œå•å…ƒæµ‹è¯•ç­‰å¤šä¸ªä¸»é¢˜ï¼Œä¸ºé‚£äº›æœ‰å…´è¶£å¼€å‘è‡ªå·±æ¡†æ¶çš„äººæä¾›äº†å…¨é¢çš„èµ„æºã€‚è¯¥æ–‡ä»¶å¯åœ¨GitBookä¸Šè·å¾—ï¼Œå¹¶å®šæœŸæ›´æ–°ã€‚\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<p>æ ¹æ®æä¾›çš„æ–‡æ¡£ç‰‡æ®µï¼Œè¿™ä»½æ–‡æ¡£ä¸»è¦æ˜¯ä¸€æœ¬å…³äºå¼€å‘æ¡†æ¶çš„æ•™ç¨‹ã€‚ä½œè€…ä»‹ç»äº†ä¸€ä¸ªåä¸ºMaomiçš„å¼€å‘æ¡†æ¶ï¼Œå¼ºè°ƒå…¶ç®€å•ã€ç®€æ´ï¼Œå¹¶æåˆ°è¯¥æ¡†æ¶å…·æœ‰å¤šä¸ªæ¨¡å—ï¼ŒåŒ…æ‹¬æ¨¡å—åŒ–å’Œè‡ªåŠ¨æœåŠ¡æ³¨å†Œã€å¤šè¯­è¨€ã€äº‹ä»¶æ€»çº¿å’ŒWebç­‰ã€‚æ–‡æ¡£ç›®å½•åˆ—å‡ºäº†å„ç« èŠ‚çš„å†…å®¹ï¼Œæ¶µç›–äº†ä»æ¡†æ¶ä½¿ç”¨æ–¹æ³•åˆ°è®¾è®¡å’Œå®ç°çš„å…¨è¿‡ç¨‹ã€‚æ¯ä¸ªç« èŠ‚éƒ½åŒ…å«äº†è¯¦ç»†çš„ä»‹ç»å’Œç¤ºä¾‹ï¼Œä¾‹å¦‚æ¨¡å—åŒ–å’Œè‡ªåŠ¨æœåŠ¡æ³¨å†Œã€æ•…éšœè¯Šæ–­å’Œæ—¥å¿—ã€é…ç½®å’Œé€‰é¡¹ã€HTTPåº”ç”¨å¼€å‘ã€äº‹ä»¶æ€»çº¿æ¡†æ¶çš„è®¾è®¡ç­‰ã€‚è¯¥æ–‡æ¡£æ—¨åœ¨å¸®åŠ©è¯»è€…äº†è§£æ¡†æ¶è®¾è®¡çš„æ€è·¯å’Œå®ç°æ–¹æ³•ï¼Œä»¥åŠå¦‚ä½•ä»é›¶å¼€å§‹æ„å»ºè‡ªå·±çš„å¼€å‘æ¡†æ¶ã€‚</p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p>æ–‡ç« çš„ä½œè€…æ˜¯ç—´è€…å·¥è‰¯ã€‚</p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma,FAISS,VectorStore\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT,QA_PROMPT\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import date\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from lang_funcs import (load_docs_by_extension,split_docs,\n",
    "        create_vectorstore_faiss,create_vectorstore,\n",
    "        load_openai_embeddings,load_huggingface_embeddings,\n",
    "        create_knowledge_chain,create_summarize_chain,create_llm_openai,read_toml\n",
    ")\n",
    "\n",
    "\n",
    "config = read_toml(\"./config.toml\")\n",
    "\n",
    "chat = create_llm_openai( apikey=config[\"openai\"][\"api_key\"],\n",
    "                         apibase=config[\"openai\"][\"url\"])\n",
    "\n",
    "#embeddings = load_openai_embeddings()\n",
    "embeddings = load_huggingface_embeddings('all-MiniLM-L6-v2')\n",
    "\n",
    "doc_url = \"https://maomi.whuanle.cn/\"\n",
    "\n",
    "documents = load_docs_by_extension(doc_url)\n",
    "#documents = load_docs_by_extension('./README.md')\n",
    "\n",
    "print (f'There are {len(documents)} document(s) in this document.')\n",
    "print (f'There are {len(documents[0].page_content)} characters in the first page of your document.')\n",
    " \n",
    "#vectorstore = create_vectorstore(documents,embeddings)\n",
    "vectorstore = create_vectorstore_faiss(documents,embeddings,\"russian-offensive-campaign\")\n",
    "\n",
    "chain = create_summarize_chain(chat)\n",
    "summ = chain({\"input_documents\": documents}, return_only_outputs=True)\n",
    "print(summ['output_text'])\n",
    "\n",
    "Q = create_knowledge_chain(chat,vectorstore.as_retriever())\n",
    "\n",
    "result =  Q({\"question\":\"è¯·è¯¦ç»†è®²ä¸€ä¸‹è¿™ä¸ªæ–‡æ¡£ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆ?\"})[\"answer\"].strip()\n",
    "\n",
    "display(Markdown(f\"<p>{result}</p>\"))\n",
    "\n",
    "\n",
    "result =  Q({\"question\":\"è¿™ç¯‡æ–‡ç« çš„ä½œè€…æ˜¯è°?\"})[\"answer\"].strip()\n",
    "\n",
    "display(Markdown(f\"<p>{result}</p>\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'city'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m tools \u001b[38;5;241m=\u001b[39m load_tools([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mddg-search\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm-math\u001b[39m\u001b[38;5;124m\"\u001b[39m], llm\u001b[38;5;241m=\u001b[39mchat)\n\u001b[1;32m      8\u001b[0m agent1 \u001b[38;5;241m=\u001b[39m initialize_agent(\n\u001b[1;32m      9\u001b[0m     tools \u001b[38;5;241m+\u001b[39m [time,weather,note],\n\u001b[1;32m     10\u001b[0m     llm\u001b[38;5;241m=\u001b[39mchat,\n\u001b[1;32m     11\u001b[0m     agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mCHAT_ZERO_SHOT_REACT_DESCRIPTION,\n\u001b[1;32m     12\u001b[0m     handle_parsing_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m  agent1\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæ‰“å¼€è®°å½•æœ¬\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m     18\u001b[0m result \u001b[38;5;241m=\u001b[39m  agent1\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mä»Šå¤©æ˜¯å‡ å·?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:151\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    146\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m     inputs,\n\u001b[1;32m    148\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:279\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    277\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing some input keys: {'city'}"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentType,initialize_agent\n",
    "from lang_tools import *\n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=chat)\n",
    "\n",
    "agent1 = initialize_agent(\n",
    "    tools + [time,weather,note],\n",
    "    llm=chat,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True)\n",
    "\n",
    "result =  agent1.invoke(\"æ‰“å¼€è®°å½•æœ¬\")\n",
    "print(result)\n",
    "\n",
    "# result =  agent1.invoke(\"ä»Šå¤©æ˜¯å‡ å·?\")\n",
    "# print(result)\n",
    "# result =  agent1.invoke(\"ä»Šå¤©ä¸Šæµ·çš„å¤©æ°”æ€ä¹ˆæ ·?\")\n",
    "# print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
