{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化Lanchain\n",
    "# 安装依赖\n",
    "* 运行环境: python 3.11.8 , conda\n",
    "* 开发环境: langchain v0.1.11 , openai v0.28.1\n",
    "```sh \n",
    "conda install langchain -c conda-forge\n",
    "conda install openai==v0.28.1 -c conda-forge\n",
    "conda install Chroma\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN apt-get update -y && apt-get install libmagic1 libmagic-dev -y\n",
    "%pip install python-magic-bin==0.4.14\n",
    "%pip install python-libmagic\n",
    "%pip install unstructured\n",
    "%pip install bilibili-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain-openai\n",
    "%pip install Chroma\n",
    "%pip install -U duckduckgo-search\n",
    "%pip install faiss-cpu\n",
    "%pip install huggingface-hub\n",
    "%pip install -U langchain-community faiss-cpu langchain-openai tiktoken\n",
    "%pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (ChatPromptTemplate,PromptTemplate,SystemMessagePromptTemplate,\n",
    "                               AIMessagePromptTemplate,HumanMessagePromptTemplate,)\n",
    "from langchain.schema import ( HumanMessage, SystemMessage, AIMessage )\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_BASE'] = 'https://openai.api2d.net/v1'\n",
    "os.environ['OPENAI_API_KEY'] = 'fk224285-rmfTvLRKQyarQdyF5YBX6IlfKVKTj1y1'\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我不知道' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chat.predict_messages([\n",
    "  SystemMessage(content=\"你是一个对人工智能一无所知的聊天机器人。当你被问及人工智能时，你必须说“我不知道”\"),\n",
    "  HumanMessage(content=\"你知道什么是AI吗?\")\n",
    "])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你今天早上吃了吗？' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "system_template=\"You are a professional translator that translates {src_lang} to {dst_lang}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template=\"{user_input}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "message = chat_prompt.format_prompt(\n",
    "    src_lang=\"English\",\n",
    "    dst_lang=\"Chinese\", \n",
    "    user_input=\"Did you eat in this morning?\"\n",
    ").to_messages()\n",
    "\n",
    "response = chat.predict_messages(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hex code for the color green is #008000.\n",
      "The hex code for the color red is #FF0000.\n",
      "The hex code for the color yellow is #FFFF00.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"color\"],\n",
    "    template=\"What is the hex code of color {color}?\",\n",
    ")\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "\n",
    "print(chain.run(\"green\"))\n",
    "print(chain.run(\"red\"))\n",
    "print(chain.run(\"yellow\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, LangChain!', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Hey!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Where are you?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='By your side', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory( k=1)\n",
    "memory.save_context({\"input\": \"Hi, LangChain!\"}, {\"output\": \"Hey!\"})\n",
    "memory.save_context({\"input\": \"Where are you?\"}, {\"output\": \"By your side\"})\n",
    "\n",
    "memory.chat_memory.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m我需要查一下中国尊和哈利法塔的高度，然后比较它们的差距。\n",
      "Action: duckduckgo_search\n",
      "Action Input: 中国尊高度\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m本页面列举了中国大陆目前最高的10座高楼，包括上海中心大厦、平安金融中心、高银金融117、广州塔等，以及其他港澳台地区的两座高楼。每座高楼都有其高度、城市、建成年份、设计特点和观光厅等信息，供高楼爱好者和建筑爱好者参考。 上海中心大厦 标准高度： 632 米 (2073 英尺) 屋顶高度： 587 米 楼层数： 128 观光厅高度： 552 米 用途： 办公，酒店，观光，书店，博物馆，零售 建成年份： 2015 所在城市： 上海 中国尊高度528米，地上108层，地下7层。 其自下而上的菱形机理，源于中国传统器皿之一——竹器。 中国人爱竹，竹比作君子，淡雅有气节，自古有\"不可居无竹\"之语。 建筑顶部的空间设计取自\"孔明灯\"的形态意向，呈冉冉上升之态。 在柔美而赋有寓意的外形设计下，技术的更新运用也让\"中国尊\"有了更多亮点，取得了多个世界第一。 智能顶升钢平台、永临结合消防系统、BIM技术全周期应用、完善的消防系统、抗震能力、低碳环保的设计贯穿于中国尊各个细节中，通过调节建筑物的高度结构和方位朝向，充分利用冬季阳光和夏季自然风的流动；建立起一套区域能源系统，实现区域集中供冷供热系统，减少20%-40%的能源消耗。 此外，中国尊使用的电梯是世界首创的服务高度超500米跃层电梯。 🎉答案是：目前，中国尊作为商务办公大楼，并未向公众开放观光服务，主要接待的是内部工作人员。 也就是说，暂时无法像游览其他城市观景台那样，登上中国尊顶端饱览京城美景。 该大厦坐落在北京市商务中心区的核心地带，东起金和东路，南接规划中的绿地，西至金和路，北靠光华路。 🌈尽管如此，\"中国尊\"的建筑设计和工程成就仍然值得我们一探究竟。 其设计理念源自中国古代礼器\"尊\"，寓意着庄重与崇高。 建筑外形自下而上逐渐收紧再放大，形如古代酒器\"樽\"，同时融入了竹编、孔明灯以及城门等中国传统元素，巧妙地将东方神韵与现代摩天大楼相结合。 💡值得一提的是，\"中国尊\"在工程技术方面创下了多项世界之最和国内纪录。 三、总结 北京中国尊的结构与力学之美不仅仅体现在其外观上，更体现在其内在的设计理念和施工技术上。 它是中国建筑技术发展的一个缩影，也是世界建筑史上的一个杰作。通过解构其结构与力学之美，可以更加深入地了解这座建筑的魅力和价值。\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我需要查一下哈利法塔的高度。\n",
      "Action: duckduckgo_search\n",
      "Action Input: 哈利法塔高度\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. 哈利法塔. 哈利法塔. 标准高度： 828 米 (2717 英尺) 总高度： 829.8 米 屋顶高度： 585 米 楼层数： 163 观光厅高度： 448 米 & 555 米 建成年份： 2010 用途： 办公，酒店，住宅，观光，信号发射 所在城市： 迪拜 哈利法塔前称迪拜塔，自2009年建成以来依据总高度和标准高度两种测量标准测量的全世界 ... 哈利法塔的高度不仅仅是为了刷新纪录，更是体现了迪拜对于建筑技术和工程的追求和突破。 为了达到这一高度，工程师们不仅使用了大量的混凝土和钢筋，还利用了先进的建筑技术和设备，如大型起重机和垂直泵等。 哈利法塔（阿拉伯文：برج خليفة‎，拉丁化：burj khalifah‎，英文：Burj Khalifa Tower），原名迪拜塔，又稱 迪拜 大廈或比斯迪拜塔。. 哈利法塔高828米，樓層總數162層，造價15億美元，大廈本身的修建耗資至少10億美元，還不包括其內部大型購物中心、湖泊和稍 ... 哈利法塔，世界第一高楼!这座令人惊叹的建筑屹立在阿拉伯联合酋长国的迪拜，高度达到了惊人的828米。它的独特之处不仅仅是高度，还包括162层楼的壮丽设计和超现代的设施。 让我们先来看看这座建筑的惊人数据。为… 哈利法塔高828米（2717英尺），是迄今为止世界上最高的摩天大楼，2007年从台湾北部的台北101大楼手中接过了头把交椅，当时的高度为509米，有106层。 它还超过了加拿大国家塔等建筑，其高度超过553米，以及美国全国广播公司在北达科他州的KVLY-TV电信塔，其高度 ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m现在我需要计算中国尊和哈利法塔的高度差。\n",
      "Action: Calculator\n",
      "Action Input: 828 - 528\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 300\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我现在知道中国尊和哈利法塔的高度差是300米。\n",
      "Final Answer: 300 米\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'300 米'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = \"socks5h://127.0.0.1:7890\" \n",
    "os.environ['https_proxy'] = \"socks5h://127.0.0.1:7890\" \n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=chat)\n",
    "agent = initialize_agent(tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "agent.run(\"中国尊和哈利法塔?它们相差多高? 它们谁最高? 使用中文回答,并返回数值\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 document(s) in this document.\n",
      "There are 28164 characters in the first page of your document.\n",
      "Creating the embeddings using FAISS\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<p>这个文档主要内容是关于俄罗斯对乌克兰的进攻行动的评估报告。报告包括了关于瓦格纳集团停止从监狱招募士兵、克里姆林宫为乌克兰战争准备的措施、一位与瓦格纳集团有关的俄罗斯军事博主呼吁解雇俄罗斯国防部长谢尔盖·绍伊古、以及克里姆林宫不愿意遏制极端民族主义亲战争人物的言论等内容。此外，报告还包括了俄罗斯在乌克兰东部的主要进攻行动、支持行动、动员和力量生成努力、以及在俄罗斯占领区域的活动等方面的详细描述。</p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023年2月9日的俄罗斯进攻战役评估提供了有关乌克兰冲突各个方面的更新。关键点包括瓦格纳集团的招募实践，俄罗斯努力为一场持久战争做好国防工业准备，要求解雇俄罗斯国防部长，以及在乌克兰东部继续进行攻势行动。报告还强调了俄罗斯在不同地区的军事活动，包括卢甘斯克、顿涅茨克和扎波罗热州，以及俄罗斯占领领土和白俄罗斯的发展。评估未涵盖俄罗斯的战争罪行，但谴责这些行为。该报告基于公开可获得的信息和来源。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma,FAISS,VectorStore\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT,QA_PROMPT\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import date\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from lang_funcs import (load_docs_by_extension,split_docs,\n",
    "        create_vectorstore_faiss,create_vectorstore,\n",
    "        load_openai_embeddings,load_huggingface_embeddings,\n",
    "        create_knowledge_chain,create_summarize_chain,create_llm_openai\n",
    ")\n",
    "\n",
    "\n",
    "chat = create_llm_openai( apikey='fk224285-rmfTvLRKQyarQdyF5YBX6IlfKVKTj1y1',\n",
    "                         apibase='https://openai.api2d.net/v1')\n",
    "\n",
    "#embeddings = load_openai_embeddings()\n",
    "embeddings = load_huggingface_embeddings('all-MiniLM-L6-v2')\n",
    "\n",
    "doc_url = \"https://www.understandingwar.org/backgrounder/russian-offensive-campaign-assessment-february-9-2023\"\n",
    "\n",
    "documents = load_docs_by_extension(doc_url)\n",
    "#documents = load_docs_by_extension('./README.md')\n",
    "\n",
    "print (f'There are {len(documents)} document(s) in this document.')\n",
    "print (f'There are {len(documents[0].page_content)} characters in the first page of your document.')\n",
    " \n",
    "#vectorstore = create_vectorstore(documents,embeddings)\n",
    "vectorstore = create_vectorstore_faiss(documents,embeddings,\"russian-offensive-campaign\")\n",
    "\n",
    "Q = create_knowledge_chain(chat,vectorstore.as_retriever())\n",
    "\n",
    "result =  Q({\"question\":\"请详细讲一下这个文档主要内容是什么?\"})[\"answer\"].strip()\n",
    "\n",
    "display(Markdown(f\"<p>{result}</p>\"))\n",
    "\n",
    "\n",
    "chain = create_summarize_chain(chat)\n",
    "summ = chain({\"input_documents\": documents}, return_only_outputs=True)\n",
    "\n",
    "print(summ['output_text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentType,initialize_agent\n",
    "from lang_tools import *\n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=chat)\n",
    "\n",
    "agent1 = initialize_agent(\n",
    "    tools + [time,weather,note],\n",
    "    llm=chat,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True)\n",
    "\n",
    "result =  agent1.invoke(\"打开记录本\")\n",
    "print(result)\n",
    "\n",
    "result =  agent1.invoke(\"今天是几号?\")\n",
    "print(result)\n",
    "result =  agent1.invoke(\"今天上海的天气怎么样?\")\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
