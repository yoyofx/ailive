{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åˆå§‹åŒ–Lanchain\n",
    "# å®‰è£…ä¾èµ–\n",
    "* è¿è¡Œç¯å¢ƒ: python 3.11.8 , conda\n",
    "* å¼€å‘ç¯å¢ƒ: langchain v0.1.11 , openai v0.28.1\n",
    "```sh \n",
    "conda install langchain -c conda-forge\n",
    "conda install openai==v0.28.1 -c conda-forge\n",
    "conda install Chroma\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN apt-get update -y && apt-get install libmagic1 libmagic-dev -y\n",
    "%pip install python-magic-bin==0.4.14\n",
    "%pip install python-libmagic\n",
    "%pip install unstructured\n",
    "%pip install bilibili-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain-openai\n",
    "%pip install Chroma\n",
    "%pip install -U duckduckgo-search\n",
    "%pip install faiss-cpu\n",
    "%pip install huggingface-hub\n",
    "%pip install -U langchain-community faiss-cpu langchain-openai tiktoken\n",
    "%pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (ChatPromptTemplate,PromptTemplate,SystemMessagePromptTemplate,\n",
    "                               AIMessagePromptTemplate,HumanMessagePromptTemplate,)\n",
    "from langchain.schema import ( HumanMessage, SystemMessage, AIMessage )\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_BASE'] = 'https://openai.api2d.net/v1'\n",
    "os.environ['OPENAI_API_KEY'] = 'fk224285-rmfTvLRKQyarQdyF5YBX6IlfKVKTj1y1'\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='æˆ‘ä¸çŸ¥é“' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chat.predict_messages([\n",
    "  SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªå¯¹äººå·¥æ™ºèƒ½ä¸€æ— æ‰€çŸ¥çš„èŠå¤©æœºå™¨äººã€‚å½“ä½ è¢«é—®åŠäººå·¥æ™ºèƒ½æ—¶ï¼Œä½ å¿…é¡»è¯´â€œæˆ‘ä¸çŸ¥é“â€\"),\n",
    "  HumanMessage(content=\"ä½ çŸ¥é“ä»€ä¹ˆæ˜¯AIå—?\")\n",
    "])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ ä»Šå¤©æ—©ä¸Šåƒäº†å—ï¼Ÿ' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "system_template=\"You are a professional translator that translates {src_lang} to {dst_lang}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template=\"{user_input}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "message = chat_prompt.format_prompt(\n",
    "    src_lang=\"English\",\n",
    "    dst_lang=\"Chinese\", \n",
    "    user_input=\"Did you eat in this morning?\"\n",
    ").to_messages()\n",
    "\n",
    "response = chat.predict_messages(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hex code for the color green is #008000.\n",
      "The hex code for the color red is #FF0000.\n",
      "The hex code for the color yellow is #FFFF00.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"color\"],\n",
    "    template=\"What is the hex code of color {color}?\",\n",
    ")\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "\n",
    "print(chain.run(\"green\"))\n",
    "print(chain.run(\"red\"))\n",
    "print(chain.run(\"yellow\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, LangChain!', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Hey!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Where are you?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='By your side', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory( k=1)\n",
    "memory.save_context({\"input\": \"Hi, LangChain!\"}, {\"output\": \"Hey!\"})\n",
    "memory.save_context({\"input\": \"Where are you?\"}, {\"output\": \"By your side\"})\n",
    "\n",
    "memory.chat_memory.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mæˆ‘éœ€è¦æŸ¥ä¸€ä¸‹ä¸­å›½å°Šå’Œå“ˆåˆ©æ³•å¡”çš„é«˜åº¦ï¼Œç„¶åæ¯”è¾ƒå®ƒä»¬çš„å·®è·ã€‚\n",
      "Action: duckduckgo_search\n",
      "Action Input: ä¸­å›½å°Šé«˜åº¦\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mæœ¬é¡µé¢åˆ—ä¸¾äº†ä¸­å›½å¤§é™†ç›®å‰æœ€é«˜çš„10åº§é«˜æ¥¼ï¼ŒåŒ…æ‹¬ä¸Šæµ·ä¸­å¿ƒå¤§å¦ã€å¹³å®‰é‡‘èä¸­å¿ƒã€é«˜é“¶é‡‘è117ã€å¹¿å·å¡”ç­‰ï¼Œä»¥åŠå…¶ä»–æ¸¯æ¾³å°åœ°åŒºçš„ä¸¤åº§é«˜æ¥¼ã€‚æ¯åº§é«˜æ¥¼éƒ½æœ‰å…¶é«˜åº¦ã€åŸå¸‚ã€å»ºæˆå¹´ä»½ã€è®¾è®¡ç‰¹ç‚¹å’Œè§‚å…‰å…ç­‰ä¿¡æ¯ï¼Œä¾›é«˜æ¥¼çˆ±å¥½è€…å’Œå»ºç­‘çˆ±å¥½è€…å‚è€ƒã€‚ ä¸Šæµ·ä¸­å¿ƒå¤§å¦ æ ‡å‡†é«˜åº¦ï¼š 632 ç±³ (2073 è‹±å°º) å±‹é¡¶é«˜åº¦ï¼š 587 ç±³ æ¥¼å±‚æ•°ï¼š 128 è§‚å…‰å…é«˜åº¦ï¼š 552 ç±³ ç”¨é€”ï¼š åŠå…¬ï¼Œé…’åº—ï¼Œè§‚å…‰ï¼Œä¹¦åº—ï¼Œåšç‰©é¦†ï¼Œé›¶å”® å»ºæˆå¹´ä»½ï¼š 2015 æ‰€åœ¨åŸå¸‚ï¼š ä¸Šæµ· ä¸­å›½å°Šé«˜åº¦528ç±³ï¼Œåœ°ä¸Š108å±‚ï¼Œåœ°ä¸‹7å±‚ã€‚ å…¶è‡ªä¸‹è€Œä¸Šçš„è±å½¢æœºç†ï¼Œæºäºä¸­å›½ä¼ ç»Ÿå™¨çš¿ä¹‹ä¸€â€”â€”ç«¹å™¨ã€‚ ä¸­å›½äººçˆ±ç«¹ï¼Œç«¹æ¯”ä½œå›å­ï¼Œæ·¡é›…æœ‰æ°”èŠ‚ï¼Œè‡ªå¤æœ‰\"ä¸å¯å±…æ— ç«¹\"ä¹‹è¯­ã€‚ å»ºç­‘é¡¶éƒ¨çš„ç©ºé—´è®¾è®¡å–è‡ª\"å­”æ˜ç¯\"çš„å½¢æ€æ„å‘ï¼Œå‘ˆå†‰å†‰ä¸Šå‡ä¹‹æ€ã€‚ åœ¨æŸ”ç¾è€Œèµ‹æœ‰å¯“æ„çš„å¤–å½¢è®¾è®¡ä¸‹ï¼ŒæŠ€æœ¯çš„æ›´æ–°è¿ç”¨ä¹Ÿè®©\"ä¸­å›½å°Š\"æœ‰äº†æ›´å¤šäº®ç‚¹ï¼Œå–å¾—äº†å¤šä¸ªä¸–ç•Œç¬¬ä¸€ã€‚ æ™ºèƒ½é¡¶å‡é’¢å¹³å°ã€æ°¸ä¸´ç»“åˆæ¶ˆé˜²ç³»ç»Ÿã€BIMæŠ€æœ¯å…¨å‘¨æœŸåº”ç”¨ã€å®Œå–„çš„æ¶ˆé˜²ç³»ç»Ÿã€æŠ—éœ‡èƒ½åŠ›ã€ä½ç¢³ç¯ä¿çš„è®¾è®¡è´¯ç©¿äºä¸­å›½å°Šå„ä¸ªç»†èŠ‚ä¸­ï¼Œé€šè¿‡è°ƒèŠ‚å»ºç­‘ç‰©çš„é«˜åº¦ç»“æ„å’Œæ–¹ä½æœå‘ï¼Œå……åˆ†åˆ©ç”¨å†¬å­£é˜³å…‰å’Œå¤å­£è‡ªç„¶é£çš„æµåŠ¨ï¼›å»ºç«‹èµ·ä¸€å¥—åŒºåŸŸèƒ½æºç³»ç»Ÿï¼Œå®ç°åŒºåŸŸé›†ä¸­ä¾›å†·ä¾›çƒ­ç³»ç»Ÿï¼Œå‡å°‘20%-40%çš„èƒ½æºæ¶ˆè€—ã€‚ æ­¤å¤–ï¼Œä¸­å›½å°Šä½¿ç”¨çš„ç”µæ¢¯æ˜¯ä¸–ç•Œé¦–åˆ›çš„æœåŠ¡é«˜åº¦è¶…500ç±³è·ƒå±‚ç”µæ¢¯ã€‚ ğŸ‰ç­”æ¡ˆæ˜¯ï¼šç›®å‰ï¼Œä¸­å›½å°Šä½œä¸ºå•†åŠ¡åŠå…¬å¤§æ¥¼ï¼Œå¹¶æœªå‘å…¬ä¼—å¼€æ”¾è§‚å…‰æœåŠ¡ï¼Œä¸»è¦æ¥å¾…çš„æ˜¯å†…éƒ¨å·¥ä½œäººå‘˜ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œæš‚æ—¶æ— æ³•åƒæ¸¸è§ˆå…¶ä»–åŸå¸‚è§‚æ™¯å°é‚£æ ·ï¼Œç™»ä¸Šä¸­å›½å°Šé¡¶ç«¯é¥±è§ˆäº¬åŸç¾æ™¯ã€‚ è¯¥å¤§å¦åè½åœ¨åŒ—äº¬å¸‚å•†åŠ¡ä¸­å¿ƒåŒºçš„æ ¸å¿ƒåœ°å¸¦ï¼Œä¸œèµ·é‡‘å’Œä¸œè·¯ï¼Œå—æ¥è§„åˆ’ä¸­çš„ç»¿åœ°ï¼Œè¥¿è‡³é‡‘å’Œè·¯ï¼ŒåŒ—é å…‰åè·¯ã€‚ ğŸŒˆå°½ç®¡å¦‚æ­¤ï¼Œ\"ä¸­å›½å°Š\"çš„å»ºç­‘è®¾è®¡å’Œå·¥ç¨‹æˆå°±ä»ç„¶å€¼å¾—æˆ‘ä»¬ä¸€æ¢ç©¶ç«Ÿã€‚ å…¶è®¾è®¡ç†å¿µæºè‡ªä¸­å›½å¤ä»£ç¤¼å™¨\"å°Š\"ï¼Œå¯“æ„ç€åº„é‡ä¸å´‡é«˜ã€‚ å»ºç­‘å¤–å½¢è‡ªä¸‹è€Œä¸Šé€æ¸æ”¶ç´§å†æ”¾å¤§ï¼Œå½¢å¦‚å¤ä»£é…’å™¨\"æ¨½\"ï¼ŒåŒæ—¶èå…¥äº†ç«¹ç¼–ã€å­”æ˜ç¯ä»¥åŠåŸé—¨ç­‰ä¸­å›½ä¼ ç»Ÿå…ƒç´ ï¼Œå·§å¦™åœ°å°†ä¸œæ–¹ç¥éŸµä¸ç°ä»£æ‘©å¤©å¤§æ¥¼ç›¸ç»“åˆã€‚ ğŸ’¡å€¼å¾—ä¸€æçš„æ˜¯ï¼Œ\"ä¸­å›½å°Š\"åœ¨å·¥ç¨‹æŠ€æœ¯æ–¹é¢åˆ›ä¸‹äº†å¤šé¡¹ä¸–ç•Œä¹‹æœ€å’Œå›½å†…çºªå½•ã€‚ ä¸‰ã€æ€»ç»“ åŒ—äº¬ä¸­å›½å°Šçš„ç»“æ„ä¸åŠ›å­¦ä¹‹ç¾ä¸ä»…ä»…ä½“ç°åœ¨å…¶å¤–è§‚ä¸Šï¼Œæ›´ä½“ç°åœ¨å…¶å†…åœ¨çš„è®¾è®¡ç†å¿µå’Œæ–½å·¥æŠ€æœ¯ä¸Šã€‚ å®ƒæ˜¯ä¸­å›½å»ºç­‘æŠ€æœ¯å‘å±•çš„ä¸€ä¸ªç¼©å½±ï¼Œä¹Ÿæ˜¯ä¸–ç•Œå»ºç­‘å²ä¸Šçš„ä¸€ä¸ªæ°ä½œã€‚é€šè¿‡è§£æ„å…¶ç»“æ„ä¸åŠ›å­¦ä¹‹ç¾ï¼Œå¯ä»¥æ›´åŠ æ·±å…¥åœ°äº†è§£è¿™åº§å»ºç­‘çš„é­…åŠ›å’Œä»·å€¼ã€‚\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mæˆ‘éœ€è¦æŸ¥ä¸€ä¸‹å“ˆåˆ©æ³•å¡”çš„é«˜åº¦ã€‚\n",
      "Action: duckduckgo_search\n",
      "Action Input: å“ˆåˆ©æ³•å¡”é«˜åº¦\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. å“ˆåˆ©æ³•å¡”. å“ˆåˆ©æ³•å¡”. æ ‡å‡†é«˜åº¦ï¼š 828 ç±³ (2717 è‹±å°º) æ€»é«˜åº¦ï¼š 829.8 ç±³ å±‹é¡¶é«˜åº¦ï¼š 585 ç±³ æ¥¼å±‚æ•°ï¼š 163 è§‚å…‰å…é«˜åº¦ï¼š 448 ç±³ & 555 ç±³ å»ºæˆå¹´ä»½ï¼š 2010 ç”¨é€”ï¼š åŠå…¬ï¼Œé…’åº—ï¼Œä½å®…ï¼Œè§‚å…‰ï¼Œä¿¡å·å‘å°„ æ‰€åœ¨åŸå¸‚ï¼š è¿ªæ‹œ å“ˆåˆ©æ³•å¡”å‰ç§°è¿ªæ‹œå¡”ï¼Œè‡ª2009å¹´å»ºæˆä»¥æ¥ä¾æ®æ€»é«˜åº¦å’Œæ ‡å‡†é«˜åº¦ä¸¤ç§æµ‹é‡æ ‡å‡†æµ‹é‡çš„å…¨ä¸–ç•Œ ... å“ˆåˆ©æ³•å¡”çš„é«˜åº¦ä¸ä»…ä»…æ˜¯ä¸ºäº†åˆ·æ–°çºªå½•ï¼Œæ›´æ˜¯ä½“ç°äº†è¿ªæ‹œå¯¹äºå»ºç­‘æŠ€æœ¯å’Œå·¥ç¨‹çš„è¿½æ±‚å’Œçªç ´ã€‚ ä¸ºäº†è¾¾åˆ°è¿™ä¸€é«˜åº¦ï¼Œå·¥ç¨‹å¸ˆä»¬ä¸ä»…ä½¿ç”¨äº†å¤§é‡çš„æ··å‡åœŸå’Œé’¢ç­‹ï¼Œè¿˜åˆ©ç”¨äº†å…ˆè¿›çš„å»ºç­‘æŠ€æœ¯å’Œè®¾å¤‡ï¼Œå¦‚å¤§å‹èµ·é‡æœºå’Œå‚ç›´æ³µç­‰ã€‚ å“ˆåˆ©æ³•å¡”ï¼ˆé˜¿æ‹‰ä¼¯æ–‡ï¼šØ¨Ø±Ø¬ Ø®Ù„ÙŠÙØ©â€ï¼Œæ‹‰ä¸åŒ–ï¼šburj khalifahâ€ï¼Œè‹±æ–‡ï¼šBurj Khalifa Towerï¼‰ï¼ŒåŸåè¿ªæ‹œå¡”ï¼Œåˆç¨± è¿ªæ‹œ å¤§å»ˆæˆ–æ¯”æ–¯è¿ªæ‹œå¡”ã€‚. å“ˆåˆ©æ³•å¡”é«˜828ç±³ï¼Œæ¨“å±¤ç¸½æ•¸162å±¤ï¼Œé€ åƒ¹15å„„ç¾å…ƒï¼Œå¤§å»ˆæœ¬èº«çš„ä¿®å»ºè€—è³‡è‡³å°‘10å„„ç¾å…ƒï¼Œé‚„ä¸åŒ…æ‹¬å…¶å…§éƒ¨å¤§å‹è³¼ç‰©ä¸­å¿ƒã€æ¹–æ³Šå’Œç¨ ... å“ˆåˆ©æ³•å¡”ï¼Œä¸–ç•Œç¬¬ä¸€é«˜æ¥¼!è¿™åº§ä»¤äººæƒŠå¹çš„å»ºç­‘å±¹ç«‹åœ¨é˜¿æ‹‰ä¼¯è”åˆé…‹é•¿å›½çš„è¿ªæ‹œï¼Œé«˜åº¦è¾¾åˆ°äº†æƒŠäººçš„828ç±³ã€‚å®ƒçš„ç‹¬ç‰¹ä¹‹å¤„ä¸ä»…ä»…æ˜¯é«˜åº¦ï¼Œè¿˜åŒ…æ‹¬162å±‚æ¥¼çš„å£®ä¸½è®¾è®¡å’Œè¶…ç°ä»£çš„è®¾æ–½ã€‚ è®©æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹è¿™åº§å»ºç­‘çš„æƒŠäººæ•°æ®ã€‚ä¸ºâ€¦ å“ˆåˆ©æ³•å¡”é«˜828ç±³ï¼ˆ2717è‹±å°ºï¼‰ï¼Œæ˜¯è¿„ä»Šä¸ºæ­¢ä¸–ç•Œä¸Šæœ€é«˜çš„æ‘©å¤©å¤§æ¥¼ï¼Œ2007å¹´ä»å°æ¹¾åŒ—éƒ¨çš„å°åŒ—101å¤§æ¥¼æ‰‹ä¸­æ¥è¿‡äº†å¤´æŠŠäº¤æ¤…ï¼Œå½“æ—¶çš„é«˜åº¦ä¸º509ç±³ï¼Œæœ‰106å±‚ã€‚ å®ƒè¿˜è¶…è¿‡äº†åŠ æ‹¿å¤§å›½å®¶å¡”ç­‰å»ºç­‘ï¼Œå…¶é«˜åº¦è¶…è¿‡553ç±³ï¼Œä»¥åŠç¾å›½å…¨å›½å¹¿æ’­å…¬å¸åœ¨åŒ—è¾¾ç§‘ä»–å·çš„KVLY-TVç”µä¿¡å¡”ï¼Œå…¶é«˜åº¦ ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mç°åœ¨æˆ‘éœ€è¦è®¡ç®—ä¸­å›½å°Šå’Œå“ˆåˆ©æ³•å¡”çš„é«˜åº¦å·®ã€‚\n",
      "Action: Calculator\n",
      "Action Input: 828 - 528\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 300\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mæˆ‘ç°åœ¨çŸ¥é“ä¸­å›½å°Šå’Œå“ˆåˆ©æ³•å¡”çš„é«˜åº¦å·®æ˜¯300ç±³ã€‚\n",
      "Final Answer: 300 ç±³\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'300 ç±³'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = \"socks5h://127.0.0.1:7890\" \n",
    "os.environ['https_proxy'] = \"socks5h://127.0.0.1:7890\" \n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=chat)\n",
    "agent = initialize_agent(tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "agent.run(\"ä¸­å›½å°Šå’Œå“ˆåˆ©æ³•å¡”?å®ƒä»¬ç›¸å·®å¤šé«˜? å®ƒä»¬è°æœ€é«˜? ä½¿ç”¨ä¸­æ–‡å›ç­”,å¹¶è¿”å›æ•°å€¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 document(s) in this document.\n",
      "There are 28164 characters in the first page of your document.\n",
      "Creating the embeddings using FAISS\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<p>è¿™ä¸ªæ–‡æ¡£ä¸»è¦å†…å®¹æ˜¯å…³äºä¿„ç½—æ–¯å¯¹ä¹Œå…‹å…°çš„è¿›æ”»è¡ŒåŠ¨çš„è¯„ä¼°æŠ¥å‘Šã€‚æŠ¥å‘ŠåŒ…æ‹¬äº†å…³äºç“¦æ ¼çº³é›†å›¢åœæ­¢ä»ç›‘ç‹±æ‹›å‹Ÿå£«å…µã€å…‹é‡Œå§†æ—å®«ä¸ºä¹Œå…‹å…°æˆ˜äº‰å‡†å¤‡çš„æªæ–½ã€ä¸€ä½ä¸ç“¦æ ¼çº³é›†å›¢æœ‰å…³çš„ä¿„ç½—æ–¯å†›äº‹åšä¸»å‘¼åè§£é›‡ä¿„ç½—æ–¯å›½é˜²éƒ¨é•¿è°¢å°”ç›–Â·ç»ä¼Šå¤ã€ä»¥åŠå…‹é‡Œå§†æ—å®«ä¸æ„¿æ„éåˆ¶æç«¯æ°‘æ—ä¸»ä¹‰äº²æˆ˜äº‰äººç‰©çš„è¨€è®ºç­‰å†…å®¹ã€‚æ­¤å¤–ï¼ŒæŠ¥å‘Šè¿˜åŒ…æ‹¬äº†ä¿„ç½—æ–¯åœ¨ä¹Œå…‹å…°ä¸œéƒ¨çš„ä¸»è¦è¿›æ”»è¡ŒåŠ¨ã€æ”¯æŒè¡ŒåŠ¨ã€åŠ¨å‘˜å’ŒåŠ›é‡ç”ŸæˆåŠªåŠ›ã€ä»¥åŠåœ¨ä¿„ç½—æ–¯å é¢†åŒºåŸŸçš„æ´»åŠ¨ç­‰æ–¹é¢çš„è¯¦ç»†æè¿°ã€‚</p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023å¹´2æœˆ9æ—¥çš„ä¿„ç½—æ–¯è¿›æ”»æˆ˜å½¹è¯„ä¼°æä¾›äº†æœ‰å…³ä¹Œå…‹å…°å†²çªå„ä¸ªæ–¹é¢çš„æ›´æ–°ã€‚å…³é”®ç‚¹åŒ…æ‹¬ç“¦æ ¼çº³é›†å›¢çš„æ‹›å‹Ÿå®è·µï¼Œä¿„ç½—æ–¯åŠªåŠ›ä¸ºä¸€åœºæŒä¹…æˆ˜äº‰åšå¥½å›½é˜²å·¥ä¸šå‡†å¤‡ï¼Œè¦æ±‚è§£é›‡ä¿„ç½—æ–¯å›½é˜²éƒ¨é•¿ï¼Œä»¥åŠåœ¨ä¹Œå…‹å…°ä¸œéƒ¨ç»§ç»­è¿›è¡Œæ”»åŠ¿è¡ŒåŠ¨ã€‚æŠ¥å‘Šè¿˜å¼ºè°ƒäº†ä¿„ç½—æ–¯åœ¨ä¸åŒåœ°åŒºçš„å†›äº‹æ´»åŠ¨ï¼ŒåŒ…æ‹¬å¢ç”˜æ–¯å…‹ã€é¡¿æ¶…èŒ¨å…‹å’Œæ‰æ³¢ç½—çƒ­å·ï¼Œä»¥åŠä¿„ç½—æ–¯å é¢†é¢†åœŸå’Œç™½ä¿„ç½—æ–¯çš„å‘å±•ã€‚è¯„ä¼°æœªæ¶µç›–ä¿„ç½—æ–¯çš„æˆ˜äº‰ç½ªè¡Œï¼Œä½†è°´è´£è¿™äº›è¡Œä¸ºã€‚è¯¥æŠ¥å‘ŠåŸºäºå…¬å¼€å¯è·å¾—çš„ä¿¡æ¯å’Œæ¥æºã€‚\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma,FAISS,VectorStore\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT,QA_PROMPT\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import date\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from lang_funcs import (load_docs_by_extension,split_docs,\n",
    "        create_vectorstore_faiss,create_vectorstore,\n",
    "        load_openai_embeddings,load_huggingface_embeddings,\n",
    "        create_knowledge_chain,create_summarize_chain,create_llm_openai\n",
    ")\n",
    "\n",
    "\n",
    "chat = create_llm_openai( apikey='fk224285-rmfTvLRKQyarQdyF5YBX6IlfKVKTj1y1',\n",
    "                         apibase='https://openai.api2d.net/v1')\n",
    "\n",
    "#embeddings = load_openai_embeddings()\n",
    "embeddings = load_huggingface_embeddings('all-MiniLM-L6-v2')\n",
    "\n",
    "doc_url = \"https://www.understandingwar.org/backgrounder/russian-offensive-campaign-assessment-february-9-2023\"\n",
    "\n",
    "documents = load_docs_by_extension(doc_url)\n",
    "#documents = load_docs_by_extension('./README.md')\n",
    "\n",
    "print (f'There are {len(documents)} document(s) in this document.')\n",
    "print (f'There are {len(documents[0].page_content)} characters in the first page of your document.')\n",
    " \n",
    "#vectorstore = create_vectorstore(documents,embeddings)\n",
    "vectorstore = create_vectorstore_faiss(documents,embeddings,\"russian-offensive-campaign\")\n",
    "\n",
    "Q = create_knowledge_chain(chat,vectorstore.as_retriever())\n",
    "\n",
    "result =  Q({\"question\":\"è¯·è¯¦ç»†è®²ä¸€ä¸‹è¿™ä¸ªæ–‡æ¡£ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆ?\"})[\"answer\"].strip()\n",
    "\n",
    "display(Markdown(f\"<p>{result}</p>\"))\n",
    "\n",
    "\n",
    "chain = create_summarize_chain(chat)\n",
    "summ = chain({\"input_documents\": documents}, return_only_outputs=True)\n",
    "\n",
    "print(summ['output_text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentType,initialize_agent\n",
    "from lang_tools import *\n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=chat)\n",
    "\n",
    "agent1 = initialize_agent(\n",
    "    tools + [time,weather,note],\n",
    "    llm=chat,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True)\n",
    "\n",
    "result =  agent1.invoke(\"æ‰“å¼€è®°å½•æœ¬\")\n",
    "print(result)\n",
    "\n",
    "result =  agent1.invoke(\"ä»Šå¤©æ˜¯å‡ å·?\")\n",
    "print(result)\n",
    "result =  agent1.invoke(\"ä»Šå¤©ä¸Šæµ·çš„å¤©æ°”æ€ä¹ˆæ ·?\")\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
