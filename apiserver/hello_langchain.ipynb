{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化Lanchain\n",
    "# 安装依赖\n",
    "* 运行环境: python 3.11.8 , conda\n",
    "* 开发环境: langchain v0.1.11 , openai v0.28.1\n",
    "```sh \n",
    "conda install langchain -c conda-forge\n",
    "conda install openai==v0.28.1 -c conda-forge\n",
    "conda install Chroma\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN apt-get update -y && apt-get install libmagic1 libmagic-dev -y\n",
    "%pip install python-magic-bin==0.4.14\n",
    "%pip install python-libmagic\n",
    "%pip install unstructured\n",
    "%pip install bilibili-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain-openai\n",
    "%pip install Chroma\n",
    "%pip install -U duckduckgo-search\n",
    "%pip install faiss-cpu\n",
    "%pip install huggingface-hub\n",
    "%pip install -U langchain-community faiss-cpu langchain-openai tiktoken\n",
    "%pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (ChatPromptTemplate,PromptTemplate,SystemMessagePromptTemplate,\n",
    "                               AIMessagePromptTemplate,HumanMessagePromptTemplate,)\n",
    "from langchain.schema import ( HumanMessage, SystemMessage, AIMessage )\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from lang_funcs import read_toml,create_llm_openai\n",
    "import os\n",
    "\n",
    "config = read_toml(\"./config.toml\")\n",
    "\n",
    "chat = create_llm_openai( apikey=config[\"openai\"][\"api_key\"],\n",
    "                         apibase=config[\"openai\"][\"url\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoyofx/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict_messages` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我不知道' response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chat.predict_messages([\n",
    "  SystemMessage(content=\"你是一个对人工智能一无所知的聊天机器人。当你被问及人工智能时，你必须说“我不知道”\"),\n",
    "  HumanMessage(content=\"你知道什么是AI吗?\")\n",
    "])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你今天早上吃了吗？' response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "system_template=\"You are a professional translator that translates {src_lang} to {dst_lang}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template=\"{user_input}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "message = chat_prompt.format_prompt(\n",
    "    src_lang=\"English\",\n",
    "    dst_lang=\"Chinese\", \n",
    "    user_input=\"Did you eat in this morning?\"\n",
    ").to_messages()\n",
    "\n",
    "response = chat.predict_messages(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoyofx/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hex code for the color green is #008000.\n",
      "The hexadecimal code for the color red is #FF0000. In hexadecimal notation, colors are represented using a combination of six digits, where each pair of digits represents the intensity of red, green, and blue (RGB) in the color. In this case, the red intensity is at its maximum, while green and blue intensities are at their minimum, resulting in the color red.\n",
      "The hex code for the color yellow is #FFFF00.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"color\"],\n",
    "    template=\"What is the hex code of color {color}?\",\n",
    ")\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "\n",
    "print(chain.run(\"green\"))\n",
    "print(chain.run(\"red\"))\n",
    "print(chain.run(\"yellow\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, LangChain!', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Hey!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Where are you?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='By your side', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory( k=1)\n",
    "memory.save_context({\"input\": \"Hi, LangChain!\"}, {\"output\": \"Hey!\"})\n",
    "memory.save_context({\"input\": \"Where are you?\"}, {\"output\": \"By your side\"})\n",
    "\n",
    "memory.chat_memory.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m我需要查一下中国尊和哈利法塔的高度，然后比较它们的差距。\n",
      "Action: duckduckgo_search\n",
      "Action Input: 中国尊高度\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m本页面列举了中国大陆目前最高的10座高楼，包括上海中心大厦、平安金融中心、高银金融117、广州塔等，以及其他港澳台地区的两座高楼。每座高楼都有其高度、城市、建成年份、设计特点和观光厅等信息，供高楼爱好者和建筑爱好者参考。 上海中心大厦 标准高度： 632 米 (2073 英尺) 屋顶高度： 587 米 楼层数： 128 观光厅高度： 552 米 用途： 办公，酒店，观光，书店，博物馆，零售 建成年份： 2015 所在城市： 上海 中国尊高度528米，地上108层，地下7层。 其自下而上的菱形机理，源于中国传统器皿之一——竹器。 中国人爱竹，竹比作君子，淡雅有气节，自古有\"不可居无竹\"之语。 建筑顶部的空间设计取自\"孔明灯\"的形态意向，呈冉冉上升之态。 在柔美而赋有寓意的外形设计下，技术的更新运用也让\"中国尊\"有了更多亮点，取得了多个世界第一。 智能顶升钢平台、永临结合消防系统、BIM技术全周期应用、完善的消防系统、抗震能力、低碳环保的设计贯穿于中国尊各个细节中，通过调节建筑物的高度结构和方位朝向，充分利用冬季阳光和夏季自然风的流动；建立起一套区域能源系统，实现区域集中供冷供热系统，减少20%-40%的能源消耗。 此外，中国尊使用的电梯是世界首创的服务高度超500米跃层电梯。 🎉答案是：目前，中国尊作为商务办公大楼，并未向公众开放观光服务，主要接待的是内部工作人员。 也就是说，暂时无法像游览其他城市观景台那样，登上中国尊顶端饱览京城美景。 该大厦坐落在北京市商务中心区的核心地带，东起金和东路，南接规划中的绿地，西至金和路，北靠光华路。 🌈尽管如此，\"中国尊\"的建筑设计和工程成就仍然值得我们一探究竟。 其设计理念源自中国古代礼器\"尊\"，寓意着庄重与崇高。 建筑外形自下而上逐渐收紧再放大，形如古代酒器\"樽\"，同时融入了竹编、孔明灯以及城门等中国传统元素，巧妙地将东方神韵与现代摩天大楼相结合。 💡值得一提的是，\"中国尊\"在工程技术方面创下了多项世界之最和国内纪录。 三、总结 北京中国尊的结构与力学之美不仅仅体现在其外观上，更体现在其内在的设计理念和施工技术上。 它是中国建筑技术发展的一个缩影，也是世界建筑史上的一个杰作。通过解构其结构与力学之美，可以更加深入地了解这座建筑的魅力和价值。\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我需要查一下哈利法塔的高度。\n",
      "Action: duckduckgo_search\n",
      "Action Input: 哈利法塔高度\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. 哈利法塔. 哈利法塔. 标准高度： 828 米 (2717 英尺) 总高度： 829.8 米 屋顶高度： 585 米 楼层数： 163 观光厅高度： 448 米 & 555 米 建成年份： 2010 用途： 办公，酒店，住宅，观光，信号发射 所在城市： 迪拜 哈利法塔前称迪拜塔，自2009年建成以来依据总高度和标准高度两种测量标准测量的全世界 ... 哈利法塔的高度不仅仅是为了刷新纪录，更是体现了迪拜对于建筑技术和工程的追求和突破。 为了达到这一高度，工程师们不仅使用了大量的混凝土和钢筋，还利用了先进的建筑技术和设备，如大型起重机和垂直泵等。 哈利法塔（阿拉伯文：برج خليفة‎，拉丁化：burj khalifah‎，英文：Burj Khalifa Tower），原名迪拜塔，又稱 迪拜 大廈或比斯迪拜塔。. 哈利法塔高828米，樓層總數162層，造價15億美元，大廈本身的修建耗資至少10億美元，還不包括其內部大型購物中心、湖泊和稍 ... 哈利法塔，世界第一高楼!这座令人惊叹的建筑屹立在阿拉伯联合酋长国的迪拜，高度达到了惊人的828米。它的独特之处不仅仅是高度，还包括162层楼的壮丽设计和超现代的设施。 让我们先来看看这座建筑的惊人数据。为… 哈利法塔高828米（2717英尺），是迄今为止世界上最高的摩天大楼，2007年从台湾北部的台北101大楼手中接过了头把交椅，当时的高度为509米，有106层。 它还超过了加拿大国家塔等建筑，其高度超过553米，以及美国全国广播公司在北达科他州的KVLY-TV电信塔，其高度 ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m现在我需要计算中国尊和哈利法塔的高度差。\n",
      "Action: Calculator\n",
      "Action Input: 828 - 528\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 300\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我现在知道中国尊和哈利法塔的高度差是300米。\n",
      "Final Answer: 300 米\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'300 米'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = \"socks5h://127.0.0.1:7890\" \n",
    "os.environ['https_proxy'] = \"socks5h://127.0.0.1:7890\" \n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=chat)\n",
    "agent = initialize_agent(tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "agent.run(\"中国尊和哈利法塔?它们相差多高? 它们谁最高? 使用中文回答,并返回数值\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 document(s) in this document.\n",
      "There are 4240 characters in the first page of your document.\n",
      "Creating the embeddings using FAISS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoyofx/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该文件是对Maomi开发框架的文档。由赤褶工良撰写，涵盖了模块化、自动服务注册、故障诊断、日志记录、配置、序列化、多语言支持、HTTP应用程序开发、事件总线框架设计、动态代码生成、Web框架定制和对象映射框架等各个方面。它提供了对Maomi设计和实现的深入见解，旨在帮助开发人员理解框架的使用和设计原则。该框架包含62个项目，涵盖了诊断工具、日志框架和单元测试等多个主题，为那些有兴趣开发自己框架的人提供了全面的资源。该文件可在GitBook上获得，并定期更新。\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<p>根据提供的文档片段，这份文档主要是一本关于开发框架的教程。作者介绍了一个名为Maomi的开发框架，强调其简单、简洁，并提到该框架具有多个模块，包括模块化和自动服务注册、多语言、事件总线和Web等。文档目录列出了各章节的内容，涵盖了从框架使用方法到设计和实现的全过程。每个章节都包含了详细的介绍和示例，例如模块化和自动服务注册、故障诊断和日志、配置和选项、HTTP应用开发、事件总线框架的设计等。该文档旨在帮助读者了解框架设计的思路和实现方法，以及如何从零开始构建自己的开发框架。</p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p>文章的作者是痴者工良。</p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma,FAISS,VectorStore\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT,QA_PROMPT\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import date\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from lang_funcs import (load_docs_by_extension,split_docs,\n",
    "        create_vectorstore_faiss,create_vectorstore,\n",
    "        load_openai_embeddings,load_huggingface_embeddings,\n",
    "        create_knowledge_chain,create_summarize_chain,create_llm_openai,read_toml\n",
    ")\n",
    "\n",
    "\n",
    "config = read_toml(\"./config.toml\")\n",
    "\n",
    "chat = create_llm_openai( apikey=config[\"openai\"][\"api_key\"],\n",
    "                         apibase=config[\"openai\"][\"url\"])\n",
    "\n",
    "#embeddings = load_openai_embeddings()\n",
    "embeddings = load_huggingface_embeddings('all-MiniLM-L6-v2')\n",
    "\n",
    "doc_url = \"https://maomi.whuanle.cn/\"\n",
    "\n",
    "documents = load_docs_by_extension(doc_url)\n",
    "#documents = load_docs_by_extension('./README.md')\n",
    "\n",
    "print (f'There are {len(documents)} document(s) in this document.')\n",
    "print (f'There are {len(documents[0].page_content)} characters in the first page of your document.')\n",
    " \n",
    "#vectorstore = create_vectorstore(documents,embeddings)\n",
    "vectorstore = create_vectorstore_faiss(documents,embeddings,\"russian-offensive-campaign\")\n",
    "\n",
    "chain = create_summarize_chain(chat)\n",
    "summ = chain({\"input_documents\": documents}, return_only_outputs=True)\n",
    "print(summ['output_text'])\n",
    "\n",
    "Q = create_knowledge_chain(chat,vectorstore.as_retriever())\n",
    "\n",
    "result =  Q({\"question\":\"请详细讲一下这个文档主要内容是什么?\"})[\"answer\"].strip()\n",
    "\n",
    "display(Markdown(f\"<p>{result}</p>\"))\n",
    "\n",
    "\n",
    "result =  Q({\"question\":\"这篇文章的作者是谁?\"})[\"answer\"].strip()\n",
    "\n",
    "display(Markdown(f\"<p>{result}</p>\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'city'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m tools \u001b[38;5;241m=\u001b[39m load_tools([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mddg-search\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm-math\u001b[39m\u001b[38;5;124m\"\u001b[39m], llm\u001b[38;5;241m=\u001b[39mchat)\n\u001b[1;32m      8\u001b[0m agent1 \u001b[38;5;241m=\u001b[39m initialize_agent(\n\u001b[1;32m      9\u001b[0m     tools \u001b[38;5;241m+\u001b[39m [time,weather,note],\n\u001b[1;32m     10\u001b[0m     llm\u001b[38;5;241m=\u001b[39mchat,\n\u001b[1;32m     11\u001b[0m     agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mCHAT_ZERO_SHOT_REACT_DESCRIPTION,\n\u001b[1;32m     12\u001b[0m     handle_parsing_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m  agent1\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m打开记录本\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m     18\u001b[0m result \u001b[38;5;241m=\u001b[39m  agent1\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m今天是几号?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:151\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    146\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m     inputs,\n\u001b[1;32m    148\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:279\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    277\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing some input keys: {'city'}"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentType,initialize_agent\n",
    "from lang_tools import *\n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=chat)\n",
    "\n",
    "agent1 = initialize_agent(\n",
    "    tools + [time,weather,note],\n",
    "    llm=chat,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True)\n",
    "\n",
    "result =  agent1.invoke(\"打开记录本\")\n",
    "print(result)\n",
    "\n",
    "# result =  agent1.invoke(\"今天是几号?\")\n",
    "# print(result)\n",
    "# result =  agent1.invoke(\"今天上海的天气怎么样?\")\n",
    "# print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
